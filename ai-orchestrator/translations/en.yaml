configuration:
  dry_run_mode:
    name: Dry Run Mode
    description: "If enabled, the AI will make decisions and log them but acts as a 'simulated' execution - no actual changes will be made to Home Assistant entities. Great for testing prompt safety."
  ollama_host:
    name: Ollama Host
    description: "URL of your Ollama instance (e.g., http://localhost:11434)."
  log_level:
    name: Log Level
    description: "Verbosity of backend logs."
  ha_access_token:
    name: HA Access Token
    description: "Long-Lived Access Token for direct Home Assistant API access (bypasses Supervisor proxy)."
  decision_interval:
    name: Decision Interval
    description: "Time in seconds between AI decision loops."
  enable_gpu:
    name: Enable GPU
    description: "Enable GPU support for local Ollama instance (requires hardware support)."
  openai_api_key:
    name: OpenAI API Key
    description: "Secret API key for OpenAI (required to enable OpenAI features)."
  use_openai:
    name: Use OpenAI
    description: "Enable OpenAI as an AI provider (opt-in)."
  openai_fast_model:
    name: OpenAI Fast Model
    description: "Model used for quick responses (e.g., gpt-4o-mini)."
  openai_smart_model:
    name: OpenAI Smart Model
    description: "Model used for complex reasoning (e.g., gpt-4o)."
  openai_embedding_model:
    name: OpenAI Embedding Model
    description: "Model used for embeddings (e.g., text-embedding-3-small)."
  use_openai_for_dashboard:
    name: Use OpenAI for Dashboard
    description: "Use OpenAI for visual dashboard generation instead of local/Gemini."
